{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T00:54:23.687650Z",
     "start_time": "2018-11-25T00:54:21.241577Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Read in data from dataset\n",
    "dataset = os.path.expanduser('~/data/question_pair_dataframe.csv')\n",
    "data = pd.read_csv(dataset,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T00:54:25.938994Z",
     "start_time": "2018-11-25T00:54:25.922247Z"
    }
   },
   "outputs": [],
   "source": [
    "data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T00:55:31.521364Z",
     "start_time": "2018-11-25T00:55:11.075987Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Read in GloVe word embeddings\n",
    "embeddings_50d = \"../../word_embeddings/glove.6B/glove.6B.100d.text\"\n",
    "embeddings_100d = \"../../word_embeddings/glove.6B/glove.6B.100d.text\"\n",
    "embeddings_200d = \"../../word_embeddings/glove.6B/glove.6B.200d.text\"\n",
    "embeddings_300d = \"../../word_embeddings/glove.6B/glove.6B.300d.txt\"\n",
    "\n",
    "embeddings = pd.read_table(embeddings_300d, delim_whitespace=True, index_col=0, header=None, quoting=csv.QUOTE_NONE)\n",
    "embedding_dim = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pre-processing step below takes about ~4 hours to complete for ~2.5 million question pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T04:49:04.605054Z",
     "start_time": "2018-11-25T00:59:23.213729Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "ws = [str(word) for word in embeddings.axes[0]]\n",
    "\n",
    "def process_sentence(sentence):\n",
    "    word_sequence = text_to_word_sequence(str(sentence))\n",
    "    return [ws.index(word) if word in ws else 0 for word in word_sequence]\n",
    "\n",
    "q1s = [process_sentence(sentence) for sentence in data.question1]\n",
    "q2s = [process_sentence(sentence) for sentence in data.question2]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"question1\" : q1s,\n",
    "    \"question2\" : q2s,\n",
    "    \"labels\" : data.labels\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T04:49:10.942408Z",
     "start_time": "2018-11-25T04:49:04.608827Z"
    }
   },
   "outputs": [],
   "source": [
    "max_question_length = max(max([len(str(question)) for question in df.question1],[len(str(question)) for question in df.question2]))\n",
    "print(f\"Max length: {max_question_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T14:39:08.063556Z",
     "start_time": "2018-11-25T14:38:37.922981Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "\n",
    "validation_set_size = round(0.20*len(df))\n",
    "training_set_size = len(df) - validation_set_size\n",
    "\n",
    "X = df[[\"question1\",\"question2\"]]\n",
    "Y = df[\"labels\"]\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X,Y,test_size=validation_set_size)\n",
    "\n",
    "X_train = {\n",
    "    'left': X_train.question1, \n",
    "    'right': X_train.question2\n",
    "}\n",
    "X_validation = {\n",
    "    'left': X_validation.question1, \n",
    "    'right': X_validation.question2\n",
    "}\n",
    "Y_train = Y_train.values\n",
    "Y_validation = Y_validation.values\n",
    "\n",
    "for dataset, side in itertools.product([X_train, X_validation], ['left', 'right']):\n",
    "    dataset[side] = pad_sequences(dataset[side],  maxlen=max_question_length)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Validation set size: {len(X_validation)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T14:45:40.782465Z",
     "start_time": "2018-11-25T14:45:40.458863Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Embedding, LSTM, Lambda\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "def exponent_neg_manhattan_distance(left, right):\n",
    "    return K.exp(-K.sum(K.abs(left - right), axis=1, keepdims=True))\n",
    "\n",
    "\n",
    "n_hidden_units = 32\n",
    "\n",
    "left_input = Input(shape=(max_question_length, ), dtype='int32')\n",
    "right_input = Input(shape=(max_question_length, ), dtype='int32')\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    len(embeddings), embedding_dim, input_length=max_question_length)\n",
    "embedded_left = embedding_layer(left_input)\n",
    "embedded_right = embedding_layer(right_input)\n",
    "\n",
    "lstm = LSTM(n_hidden_units)\n",
    "left_out = lstm(embedded_left)\n",
    "right_out = lstm(embedded_right)\n",
    "\n",
    "malstm_distance = Lambda(\n",
    "    function=lambda x: exponent_neg_manhattan_distance(x[0], x[1]),\n",
    "    output_shape=lambda x: (x[0][0], 1))([left_out, right_out])\n",
    "\n",
    "model = Model(inputs=[left_input, right_input], outputs=[malstm_distance])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a 6 core i9, the below takes many hours per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T14:49:00.104133Z",
     "start_time": "2018-11-25T14:46:51.968534Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adadelta\n",
    "from time import time\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 32\n",
    "num_epoch = 10\n",
    "\n",
    "model.compile(\n",
    "    loss='mean_squared_error',\n",
    "    optimizer=tf.train.GradientDescentOptimizer(0.5),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "start_time = time()\n",
    "trained = model.fit(\n",
    "    [X_train['left'], X_train['right']],\n",
    "    Y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=num_epoch,\n",
    "    validation_data=([X_validation['left'], X_validation['right']],\n",
    "                     Y_validation))\n",
    "print(\n",
    "    f\"Training finished. {num_epoch} epochs in {datetime.timedelta(seconds=time() - start_time)}.\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
