{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.1.1 University Code of Conduct \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "import re\n",
    "import requests\n",
    "import html2text\n",
    "import validators\n",
    "import itertools\n",
    "\n",
    "princeton_hr_policies_url = \"https://adminguide.stanford.edu\"\n",
    "\n",
    "def uri_validator(x):\n",
    "    try:\n",
    "        result = urlparse(x)\n",
    "        return result.scheme is not None\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def process_policy_document(policy):\n",
    "    policy_text = str(policy)\n",
    "    s = BeautifulSoup(policy_text)\n",
    "    content = s.find(\"div\",id=\"content\")\n",
    "    title = content.find(\"h1\").text\n",
    "    text = html2text.html2text(str(content))\n",
    "    return (title, text)\n",
    "\n",
    "def parse_section_links(chapter_url):\n",
    "    policy_page = requests.get(policy_section)\n",
    "    soup = BeautifulSoup(policy_page.text)\n",
    "    body = soup.findAll(\"div\", id=re.compile(\"my-policies-*\"))\n",
    "    anchors = [child.findChildren(\"a\", href=True) for child in body]\n",
    "    relative_links = [anchor[\"href\"] for anchor in list(itertools.chain(*anchors))]\n",
    "    links = [f\"{princeton_hr_policies_url}{link}\" for link in relative_links]\n",
    "    return links\n",
    "    \n",
    "    \n",
    "page = requests.get(princeton_hr_policies_url)\n",
    "soup = BeautifulSoup(page.text)\n",
    "\n",
    "# Scrape policy links from webpage\n",
    "policy_toc = soup.find(\"div\", id=\"block-bean-chapters\")\n",
    "chaptersList = policy_toc.find(\"ol\")\n",
    "policy_link_tags = policy_toc.findChildren(\"a\",href=True)\n",
    "policy_links = [el[\"href\"] for el in policy_link_tags]\n",
    "\n",
    "policy_list = []\n",
    "for policy_section in policy_links:\n",
    "    chapter_links = parse_section_links(policy_section)    \n",
    "    for link in chapter_links:\n",
    "        doc = requests.get(link)\n",
    "        policy_list.append(process_policy_document(doc.text))\n",
    "\n",
    "print(f\"Scraped {len(policy_list)} policy from {princeton_hr_policies_url}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
